{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DMN-Virtual Env Replication\n",
    "In this notebook, we re-run our initial analyses from our first submission to ensure that our data continues to be accessible. Unfortunately, we discovered that many of the packages that we initially relied on depreciated. To use this code, you have two options: you can access a Docker image created by Alejandro de la Vega, which is listed on his repo <a href=\"https://github.com/adelavega/neurosynth-mfc\">here</a>. Alternatively, you can create a virtual environment with all of your dependencies set to the correct version. The latter option worked best for us. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from neurosynth.base.dataset import Dataset\n",
    "dataset = Dataset.load('neurosynth-lfc/data/data/neurosynth_60_0.6.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cognitive_topics = ['memory','categorization','switching','inhibition','priming',\n",
    "                    'social','fear','emotion','learning','reward',  \n",
    "                    'decision-making','imagery','spatial','attention','WM',\n",
    "                    'awareness','language','math','semantics','reading']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "disease_topics = ['smoking','eating-disorder','depression','schizopherenia','adhd','autism','Alzheimer-Parkinson','ptsd']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The DMN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from classification import RegionalClassifier\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifying...\n",
      "[##########] 100%\n"
     ]
    }
   ],
   "source": [
    "clf = RegionalClassifier(dataset, 'dmn-parcellation/masks/DMN.nii.gz', GaussianNB())\n",
    "clf.classify(scoring=roc_auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.63953177, 0.59314009, 0.59947901, 0.56496712])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.class_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "nicknames = pd.read_csv('neurosynth-lfc/data/v4-topics-60.txt', delimiter='\\t')\n",
    "nicknames['topic_name'] = nicknames.apply(lambda row: '_'.join([str(row.topic_number)] + row.top_words.split(' ')[0:3]), axis=1)\n",
    "nicknames = nicknames.sort_values('topic_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_importances = clf.get_formatted_importances(feature_names=nicknames.nickname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#formatted_importances.to_csv('dmn_formatted_importances.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DMN Permutations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the names of each region in the DMN\n",
    "names_70 = ['1','2','3','4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[##########] 100%\n"
     ]
    }
   ],
   "source": [
    "from classification import permute_log_odds\n",
    "lor_z = classification.permute_log_odds(clf, 1000, feature_names=nicknames.nickname, region_names = names_70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/neurosynth_env/lib/python2.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/anaconda3/envs/neurosynth_env/lib/python2.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "cog_ps = lor_z[lor_z.nickname.isin(cognitive_topics)]\n",
    "from statsmodels.sandbox.stats.multicomp import multipletests\n",
    "\n",
    "reject, p_corr, a, a1 = multipletests(cog_ps.p, alpha=0.01, method='fdr_tsbky')\n",
    "\n",
    "cog_ps['p_corr_01'] = p_corr # Adjusted p-value\n",
    "cog_ps['reject_01'] = (cog_ps.p_corr_01<0.05) & (cog_ps.lor_z > 0) # Was the null hypothesis rejected?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtaining the LOR CI's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[##########] 100%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "classification.py:233: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version\n",
      "  return overall_boot.groupby(['region', 'topic_name'])['fi'].agg({'mean' : np.mean, 'low_ci' : percentile(2.5), 'hi_ci' : percentile(97.5)}).reset_index()\n"
     ]
    }
   ],
   "source": [
    "lor_ci = classification.bootstrap_log_odds(clf, 100, feature_names=nicknames.nickname, \n",
    "                                           region_names = names_70, n_jobs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lor_ci.rename({'topic_name': 'feature'}, axis=1, inplace=True)\n",
    "lor_ci['ci_range']=lor_ci['hi_ci']-lor_ci['low_ci']\n",
    "lor_ci.drop(['hi_ci','low_ci','mean'], axis=1, inplace=True)\n",
    "lor_ci['region']=lor_ci['region'].astype(int, inplace=True)\n",
    "merge = pd.merge(formatted_importances, lor_ci, how='left', left_on=['region','feature'], right_on=['region','feature'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge.to_csv('final-output/dmn_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The MPFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifying...\n",
      "[##########] 100%\n"
     ]
    }
   ],
   "source": [
    "names_70=[1,2]\n",
    "\n",
    "clf = RegionalClassifier(dataset, 'dmn-parcellation/images/MPFC/cluster_labels_k2.nii.gz', GaussianNB())\n",
    "clf.classify(scoring=roc_auc_score)\n",
    "formatted_importances = clf.get_formatted_importances(feature_names=nicknames.nickname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.62871038, 0.62320936])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.class_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtaining the LOR CI's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[##########] 100%\n"
     ]
    }
   ],
   "source": [
    "lor_ci = classification.bootstrap_log_odds(clf, 100, feature_names=nicknames.nickname, \n",
    "                                           region_names = names_70, n_jobs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "lor_ci.rename({'topic_name': 'feature'}, axis=1, inplace=True)\n",
    "lor_ci['ci_range']=lor_ci['hi_ci']-lor_ci['low_ci']\n",
    "lor_ci.drop(['hi_ci','low_ci','mean'], axis=1, inplace=True)\n",
    "merge = pd.merge(formatted_importances, lor_ci, how='left', left_on=['region','feature'], right_on=['region','feature'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge.to_csv('final-output/mpc-data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The PCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifying...\n",
      "[##########] 100%\n"
     ]
    }
   ],
   "source": [
    "names_70=[1,2,3]\n",
    "\n",
    "clf = RegionalClassifier(dataset, 'dmn-parcellation/images/PCC/cluster_labels_k3.nii.gz', GaussianNB())\n",
    "clf.classify(scoring=roc_auc_score)\n",
    "formatted_importances = clf.get_formatted_importances(feature_names=nicknames.nickname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.57195308, 0.59751122, 0.57454637])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.class_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[##########] 100%\n"
     ]
    }
   ],
   "source": [
    "lor_ci = classification.bootstrap_log_odds(clf, 100, feature_names=nicknames.nickname, \n",
    "                                           region_names = names_70, n_jobs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "lor_ci.rename({'topic_name': 'feature'}, axis=1, inplace=True)\n",
    "lor_ci['ci_range']=lor_ci['hi_ci']-lor_ci['low_ci']\n",
    "lor_ci.drop(['hi_ci','low_ci','mean'], axis=1, inplace=True)\n",
    "merge = pd.merge(formatted_importances, lor_ci, how='left', left_on=['region','feature'], right_on=['region','feature'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge.head()\n",
    "#merge.to_csv('final-output/pcc-data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The lTPJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifying...\n",
      "[##########] 100%\n"
     ]
    }
   ],
   "source": [
    "names_70=[1,2,3]\n",
    "\n",
    "clf = RegionalClassifier(dataset, 'dmn-parcellation/images/lTPJ/cluster_labels_k3.nii.gz', GaussianNB())\n",
    "clf.classify(scoring=roc_auc_score)\n",
    "formatted_importances = clf.get_formatted_importances(feature_names=nicknames.nickname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.59309422, 0.57119875, 0.59140037])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.class_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[##########] 100%\n"
     ]
    }
   ],
   "source": [
    "lor_ci = classification.bootstrap_log_odds(clf, 100, feature_names=nicknames.nickname, \n",
    "                                           region_names = names_70, n_jobs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "lor_ci.rename({'topic_name': 'feature'}, axis=1, inplace=True)\n",
    "lor_ci['ci_range']=lor_ci['hi_ci']-lor_ci['low_ci']\n",
    "lor_ci.drop(['hi_ci','low_ci','mean'], axis=1, inplace=True)\n",
    "merge = pd.merge(formatted_importances, lor_ci, how='left', left_on=['region','feature'], right_on=['region','feature'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge.to_csv('final-output/ltpj-data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The rTPJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifying...\n",
      "[##########] 100%\n"
     ]
    }
   ],
   "source": [
    "names_70=[1,2,3]\n",
    "\n",
    "clf = RegionalClassifier(dataset, 'dmn-parcellation/images/rTPJ/cluster_labels_k3.nii.gz', GaussianNB())\n",
    "clf.classify(scoring=roc_auc_score)\n",
    "formatted_importances = clf.get_formatted_importances(feature_names=nicknames.nickname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.55625326, 0.56891932, 0.56224357])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.class_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[##########] 100%\n"
     ]
    }
   ],
   "source": [
    "lor_ci = classification.bootstrap_log_odds(clf, 100, feature_names=nicknames.nickname, \n",
    "                                           region_names = names_70, n_jobs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "lor_ci.rename({'topic_name': 'feature'}, axis=1, inplace=True)\n",
    "lor_ci['ci_range']=lor_ci['hi_ci']-lor_ci['low_ci']\n",
    "lor_ci.drop(['hi_ci','low_ci','mean'], axis=1, inplace=True)\n",
    "merge = pd.merge(formatted_importances, lor_ci, how='left', left_on=['region','feature'], right_on=['region','feature'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge.to_csv('final-output/rtpj-data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (neurosynth)",
   "language": "python",
   "name": "neurosynth"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
