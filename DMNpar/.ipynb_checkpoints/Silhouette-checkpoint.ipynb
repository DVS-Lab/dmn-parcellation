{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from neurosynth.base.dataset import Dataset\n",
    "dataset = Dataset.load(\"data/neurosynth_60_0.6.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from neurosynth.analysis.cluster import Clusterable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mask = 'masks/newLTPJ.nii.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "roi = Clusterable(dataset, mask=mask,min_studies=80,feature_threshold=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reference = Clusterable(dataset, min_studies=80,feature_threshold=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "from six import string_types\n",
    "from sklearn import decomposition as sk_decomp\n",
    "from sklearn import cluster as sk_cluster\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from os.path import exists, join\n",
    "from os import makedirs\n",
    "from nibabel import nifti1\n",
    "from neurosynth.analysis import meta\n",
    "\n",
    "\n",
    "\n",
    "reduce_reference = 'pca'\n",
    "n_components = 100\n",
    "reduce_reference = {\n",
    "                'pca': sk_decomp.RandomizedPCA,\n",
    "                'ica': sk_decomp.FastICA\n",
    "            }[reduce_reference](n_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "method = 'coactivation'\n",
    "transpose = (method == 'coactivation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reference = reference.transform(reduce_reference, transpose=transpose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "distance_metric = 'correlation'\n",
    "distances = pairwise_distances(roi.data, reference.data,\n",
    "                                       metric=distance_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_clusters = 2 The average silhouette_score is : 0.21257213953\n",
      "For n_clusters = 3 The average silhouette_score is : 0.238983224527\n",
      "For n_clusters = 4 The average silhouette_score is : 0.213386981999\n",
      "For n_clusters = 5 The average silhouette_score is : 0.219348898561\n",
      "For n_clusters = 6 The average silhouette_score is : 0.2254102484\n",
      "For n_clusters = 7 The average silhouette_score is : 0.231470628629\n",
      "For n_clusters = 8 The average silhouette_score is : 0.219869276146\n",
      "For n_clusters = 9 The average silhouette_score is : 0.209471558892\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "\n",
    "range_n_clusters = [2,3,4,5,6,7,8,9]\n",
    "\n",
    "for n_clusters in range_n_clusters:\n",
    "\n",
    "    \n",
    "    #clustering_algorithm = 'kmeans'\n",
    "    #clustering_kwargs={}\n",
    "    #clustering_algorithm = {\n",
    "     #       'kmeans': sk_cluster.KMeans,\n",
    "     #      'minik': sk_cluster.MiniBatchKMeans\n",
    "     #   }[clustering_algorithm](n_clusters, **clustering_kwargs)\n",
    "    \n",
    "    \n",
    "    # Initialize the clusterer with n_clusters value and a random generator\n",
    "    # seed of 10 for reproducibility.\n",
    "    #labels = clustering_algorithm.fit_predict(distances) \n",
    "    \n",
    "    clusterer = KMeans(n_clusters=n_clusters, random_state=10)\n",
    "    labels = clusterer.fit_predict(distances)\n",
    "    \n",
    "    # The silhouette_score gives the average value for all the samples.\n",
    "    # This gives a perspective into the density and separation of the formed\n",
    "    # clusters\n",
    "    silhouette_avg = silhouette_score(distances, labels)\n",
    "    print(\"For n_clusters =\", n_clusters,\n",
    "          \"The average silhouette_score is :\", silhouette_avg)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
